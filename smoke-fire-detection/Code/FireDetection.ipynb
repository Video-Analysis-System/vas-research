{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FireDetection.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPzhZ2c1Tjbzqz5edNUn7ZN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"zjw-UC8TQ1U7","colab_type":"code","outputId":"c5d8b229-4964-4ab3-d364-4ff92786d29f","executionInfo":{"status":"ok","timestamp":1589335851237,"user_tz":-420,"elapsed":907,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 1.x"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yJmz-mTTREAC","colab_type":"code","outputId":"0d28778c-efd6-41b4-8c01-0f4d0d87f859","executionInfo":{"status":"ok","timestamp":1589335861544,"user_tz":-420,"elapsed":4812,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ivr4Rp24RI0q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"ba662ce7-f59c-409d-cae8-4eb0b38e4864","executionInfo":{"status":"ok","timestamp":1589336066863,"user_tz":-420,"elapsed":23950,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}}},"source":["from google.colab import drive \n","drive.mount('/content/drive/')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8jRKq48ARd05","colab_type":"code","outputId":"ce2ea720-bb5b-48f3-db82-89b1d55feddd","executionInfo":{"status":"ok","timestamp":1587970302360,"user_tz":-420,"elapsed":1157,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pwd"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"BaMSW8ruRhLR","colab_type":"code","outputId":"2a5a467d-d8c6-481d-956d-f366fa452273","executionInfo":{"status":"ok","timestamp":1587970304751,"user_tz":-420,"elapsed":1159,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/Fire"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Fire\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Riar8rfSRtFa","colab_type":"code","outputId":"d180417d-4ebe-45bb-976f-c7710aa04909","executionInfo":{"status":"ok","timestamp":1587970308402,"user_tz":-420,"elapsed":2057,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import keras\n","import tensorflow\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import load_model\n","from IPython.display import display\n","from PIL import Image\n","import cv2\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","from skimage import transform\n","import os\n","import random\n","from keras.models import model_from_json\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tzpu3x3-RwIB","colab_type":"code","colab":{}},"source":["import keras\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from keras.preprocessing.image import ImageDataGenerator, load_img\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import random\n","import os\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n","from keras.models import model_from_json\n","import cv2\n","from skimage import transform\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_T--jX7RzER","colab_type":"code","colab":{}},"source":["FAST_RUN = False\n","IMAGE_WIDTH=224\n","IMAGE_HEIGHT=224\n","IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n","IMAGE_CHANNELS=3 # RGB color"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dUzaefJHSHja","colab_type":"code","colab":{}},"source":["def CNN_Classification():\n","  model = Sequential()\n","\n","  model.add(Conv2D(16, (11, 11), strides=(4, 4), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(3, 3),strides=(2, 2) ))\n","  model.add(Dropout(0.25))\n","\n","  model.add(Conv2D(20, (5, 5), activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n","  model.add(Dropout(0.25))\n","\n","  model.add(Conv2D(30, (3, 3), activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n","  model.add(Dropout(0.25))\n","\n","  model.add(Flatten())\n","  model.add(Dense(48, activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","  model.add(Dense(2, activation='softmax'))\n","\n","  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  #Save Model\n","  CarsClassification_json =model.to_json()\n","  with open('modelfire3.json', \"w\") as json_file:\n","      json_file.write(CarsClassification_json)\n","      json_file.close()  \n","  model.summary()\n","  print(model.summary())\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5AcE4VuWSNzR","colab_type":"code","outputId":"c37a365f-7268-4217-a4e9-3de1234a7aee","executionInfo":{"status":"ok","timestamp":1587975114008,"user_tz":-420,"elapsed":1194,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["pos_dir= [\"/content/drive/My Drive/Fire/Datasetnew/Fire\"]\n","neg_dir= [\"/content/drive/My Drive/Fire/Datasetnew/NoFire\"]\n","\n","for pos_path in pos_dir:\n","  print(pos_path)\n","for neg_path in neg_dir:\n","  print(neg_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Fire/Dataset/pos\n","/content/drive/My Drive/Fire/Dataset/Neutral\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"At9aMkL6ScOT","colab_type":"code","colab":{}},"source":["def Load_Image(pos_dir, neg_dir):\n","    train_images = []\n","    train_labels = []\n","\n","    for pos_path in pos_dir:\n","      Images_Positive=os.listdir(pos_path)\n","      for image in Images_Positive:\n","          path=os.path.join(pos_path,image)\n","          img = cv2.imread(path)\n","          train_images.append(transform.resize(img,(224,224,3)))\n","          l = [1,0]\n","          train_labels.append(l)\n","    for neg_path in neg_dir:\n","      Images_Negative=os.listdir(neg_path)\n","      for image in Images_Negative:\n","          path=os.path.join(neg_path,image)\n","          img = cv2.imread(path)\n","  #       print(path)\n","          train_images.append(transform.resize(img,(224,224,3)))\n","          l = [0,1]\n","          train_labels.append(l)\n","    np.save(\"train_image_fire3\",train_images)\n","    np.save(\"train_label_fire3\",train_labels)\n","    return np.array(train_images), np.array(train_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Je8xbPqnSi4p","colab_type":"code","colab":{}},"source":["def Train_Test_split(train_data, train_labels, fraction):\n","    idx = np.random.permutation(train_data.shape[0])\n","    index = int(len(train_data)*fraction)\n","    return train_data[:index], train_labels[:index], train_data[index:], train_labels[index:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_rmk6B3vSljx","colab_type":"code","colab":{}},"source":["def Train_Model(pos_dir, neg_dir, fraction):\n","    Train_Image,Lable_Image=Load_Image(pos_dir, neg_dir)\n","    fraction = 0.95\n","    train_data, train_labels, test_data, test_labels = Train_Test_split(Train_Image,Lable_Image, fraction)\n","    print (\"Train data size: \", len(train_data))\n","    print (\"Test data size: \", len(test_data))\n","    CNN=CNN_Classification()\n","    print (\"Train data shape: \", train_data.shape)\n","    print (\"Test data shape: \", test_data.shape)\n","    idx = np.random.permutation(train_data.shape[0])\n","    CNN.fit(train_data[idx], train_labels[idx], batch_size = 64, epochs = 10)\n","    #Save weight\n","    CNN.save_weights('weighfire3.h5')\n","    predicted_test_labels = np.argmax(CNN.predict(test_data), axis=1)\n","    test_labels = np.argmax(test_labels, axis=1)\n","    score = CNN.evaluate(test_data, test_labels, verbose=0)\n","    print('Test loss:', score[0])\n","    print('Test accuracy:', score[1])\n","    print (\"Actual test labels:\", test_labels)\n","    print (\"Predicted test labels:\", predicted_test_labels)\n","    print (\"Accuracy score:\", accuracy_score(test_labels, predicted_test_labels))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jgp73vPSs77","colab_type":"code","colab":{}},"source":["def Class_object(img,Loaded_Model):\n","    img_test=[]\n","    img_test.append(transform.resize(img,(224,224,3)))\n","    Input_test=np.array(img_test)\n","    print(\"Pridict: \",Loaded_Model.predict(Input_test))\n","    if(Loaded_Model.predict(Input_test)[0][0]>0.8):\n","        print(1)\n","        return 1\n","    else:\n","        print(0)\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHCf4vjRTXEi","colab_type":"code","outputId":"c5e105a5-7e35-4e54-aac0-faedbe8a041f","executionInfo":{"status":"ok","timestamp":1587975746090,"user_tz":-420,"elapsed":623894,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["if __name__ == \"__main__\":\n","    pos_dir= [\"/content/drive/My Drive/Fire/Datasetnew/Fire\"]\n","    neg_dir= [\"/content/drive/My Drive/Fire/Datasetnew/Nofire\"]\n","    fraction= 0.95;\n","    Train_Image,Lable_Image= Load_Image(pos_dir, neg_dir) \n","    Train_Image= np.load(\"train_image_fire3.npy\")\n","    Lable_Image= np.load(\"train_label_fire3.npy\")\n","    train_data, train_labels, test_data, test_labels = Train_Test_split(Train_Image,Lable_Image, fraction)\n","    print(len(train_data))\n","    CNN=CNN_Classification()\n","    print (\"Train data shape: \", train_data.shape)\n","    print (\"Test data shape: \", test_data.shape)\n","    idx = np.random.permutation(train_data.shape[0])\n","    ntrain = len(train_data)\n","    #CNN.fit(train_data[idx], train_labels[idx], batch_size = 64, step_ber_epoch = ntrain// batch_size, epochs = 10)\n","    CNN.fit(train_data[idx], train_labels[idx], batch_size = 64, epochs = 10)\n","    #Save weight\n","    CNN.save_weights('weightfire3.h5')\n","    predicted_test_labels = np.argmax(CNN.predict(test_data), axis=1)\n","    test_labels = np.argmax(test_labels, axis=1)\n","    print (\"Actual test labels:\", test_labels)\n","    print (\"Predicted test labels:\", predicted_test_labels)\n","    print (\"Accuracy score:\", accuracy_score(test_labels, predicted_test_labels))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1635\n","Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_22 (Conv2D)           (None, 54, 54, 16)        5824      \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 54, 54, 16)        64        \n","_________________________________________________________________\n","max_pooling2d_22 (MaxPooling (None, 26, 26, 16)        0         \n","_________________________________________________________________\n","dropout_29 (Dropout)         (None, 26, 26, 16)        0         \n","_________________________________________________________________\n","conv2d_23 (Conv2D)           (None, 22, 22, 20)        8020      \n","_________________________________________________________________\n","batch_normalization_30 (Batc (None, 22, 22, 20)        80        \n","_________________________________________________________________\n","max_pooling2d_23 (MaxPooling (None, 10, 10, 20)        0         \n","_________________________________________________________________\n","dropout_30 (Dropout)         (None, 10, 10, 20)        0         \n","_________________________________________________________________\n","conv2d_24 (Conv2D)           (None, 8, 8, 30)          5430      \n","_________________________________________________________________\n","batch_normalization_31 (Batc (None, 8, 8, 30)          120       \n","_________________________________________________________________\n","max_pooling2d_24 (MaxPooling (None, 3, 3, 30)          0         \n","_________________________________________________________________\n","dropout_31 (Dropout)         (None, 3, 3, 30)          0         \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 270)               0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 48)                13008     \n","_________________________________________________________________\n","batch_normalization_32 (Batc (None, 48)                192       \n","_________________________________________________________________\n","dropout_32 (Dropout)         (None, 48)                0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 2)                 98        \n","=================================================================\n","Total params: 32,836\n","Trainable params: 32,608\n","Non-trainable params: 228\n","_________________________________________________________________\n","Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_22 (Conv2D)           (None, 54, 54, 16)        5824      \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 54, 54, 16)        64        \n","_________________________________________________________________\n","max_pooling2d_22 (MaxPooling (None, 26, 26, 16)        0         \n","_________________________________________________________________\n","dropout_29 (Dropout)         (None, 26, 26, 16)        0         \n","_________________________________________________________________\n","conv2d_23 (Conv2D)           (None, 22, 22, 20)        8020      \n","_________________________________________________________________\n","batch_normalization_30 (Batc (None, 22, 22, 20)        80        \n","_________________________________________________________________\n","max_pooling2d_23 (MaxPooling (None, 10, 10, 20)        0         \n","_________________________________________________________________\n","dropout_30 (Dropout)         (None, 10, 10, 20)        0         \n","_________________________________________________________________\n","conv2d_24 (Conv2D)           (None, 8, 8, 30)          5430      \n","_________________________________________________________________\n","batch_normalization_31 (Batc (None, 8, 8, 30)          120       \n","_________________________________________________________________\n","max_pooling2d_24 (MaxPooling (None, 3, 3, 30)          0         \n","_________________________________________________________________\n","dropout_31 (Dropout)         (None, 3, 3, 30)          0         \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 270)               0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 48)                13008     \n","_________________________________________________________________\n","batch_normalization_32 (Batc (None, 48)                192       \n","_________________________________________________________________\n","dropout_32 (Dropout)         (None, 48)                0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 2)                 98        \n","=================================================================\n","Total params: 32,836\n","Trainable params: 32,608\n","Non-trainable params: 228\n","_________________________________________________________________\n","None\n","Train data shape:  (1635, 224, 224, 3)\n","Test data shape:  (87, 224, 224, 3)\n","Epoch 1/10\n","1635/1635 [==============================] - 11s 7ms/step - loss: 0.7081 - accuracy: 0.7229\n","Epoch 2/10\n","1635/1635 [==============================] - 10s 6ms/step - loss: 0.4925 - accuracy: 0.8135\n","Epoch 3/10\n","1635/1635 [==============================] - 9s 5ms/step - loss: 0.3849 - accuracy: 0.8471\n","Epoch 4/10\n","1635/1635 [==============================] - 9s 6ms/step - loss: 0.3719 - accuracy: 0.8563\n","Epoch 5/10\n","1635/1635 [==============================] - 9s 5ms/step - loss: 0.3096 - accuracy: 0.8820\n","Epoch 6/10\n","1635/1635 [==============================] - 9s 5ms/step - loss: 0.2584 - accuracy: 0.8960\n","Epoch 7/10\n","1635/1635 [==============================] - 9s 5ms/step - loss: 0.2563 - accuracy: 0.9003\n","Epoch 8/10\n","1635/1635 [==============================] - 9s 5ms/step - loss: 0.2458 - accuracy: 0.9101\n","Epoch 9/10\n","1635/1635 [==============================] - 9s 5ms/step - loss: 0.2245 - accuracy: 0.9205\n","Epoch 10/10\n","1635/1635 [==============================] - 9s 5ms/step - loss: 0.2146 - accuracy: 0.9223\n","Actual test labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1]\n","Predicted test labels: [1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 0]\n","Accuracy score: 0.9310344827586207\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"merL8nxDvbp0","colab_type":"code","outputId":"865c2a9b-73b2-4b6a-a96e-50c50ebc81e2","executionInfo":{"status":"ok","timestamp":1587975955907,"user_tz":-420,"elapsed":3506,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Load Model\n","json_file= open('modelfire.json','r')\n","loaded_model_json= json_file.read()\n","json_file.close()\n","Loaded_Model = model_from_json(loaded_model_json)\n","#Load weights into new model\n","Loaded_Model.load_weights(\"weightfire.h5\")\n","print(\"Loaded\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MNSeyew1vkYx","colab_type":"code","colab":{}},"source":["def Load_Image(test_dir):\n","    test_images = []\n","    for test_path in test_dir:\n","      Images_Positive=os.listdir(test_path)\n","      for image in Images_Positive:\n","          path=os.path.join(test_path,image)\n","          img = cv2.imread(path)\n","          test_images.append(transform.resize(img,(224,224,3)))\n","    return np.array(test_images)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pg8lBthZvpcB","colab_type":"code","colab":{}},"source":["def load_images_from_folder(folder):\n","    images = []\n","    for filename in os.listdir(folder):\n","        img = cv2.imread(os.path.join(folder,filename))\n","        print(filename)\n","        if img is not None:\n","            images.append(img);\n","    return images"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PrSFcoJzvu5x","colab_type":"code","colab":{}},"source":["folder=\"/content/drive/My Drive/Fire/Test/Neutral\"\n","Predict_Slot=[]\n","filename_array = []\n","for filename in os.listdir(folder):\n","    images = []\n","    img = cv2.imread(os.path.join(folder,filename))\n","    images.append(transform.resize(img, (224,224,3)))\n","    images= np.array(images)\n","    if(Loaded_Model.predict(images)[0][0]>0.8):\n","      Predict_Slot.append(1)\n","      #print(\"BusySlot: %s\" % (filename))\n","      filename_array += [\"fire: %s\" % (filename)]\n","\n","    else:\n","      Predict_Slot.append(0)\n","      #print(\"FreeSlot: %s\" % (filename))\n","      filename_array += [\"nofire: %s\" % (filename)]\n","with open('Checkdata.txt', 'w') as f:\n","    for item in filename_array:\n","        f.write(\"%s\\n\" % item)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAHYyUJiwH-w","colab_type":"code","outputId":"4f042b08-ca68-45aa-b934-ef8145fde671","executionInfo":{"status":"ok","timestamp":1587976502203,"user_tz":-420,"elapsed":1064,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["#Check Free Slot\n","Index_Slot= []\n","Count=0;\n","for i in range(len(Predict_Slot)):\n","  if(Predict_Slot[i]==1):\n","    Count +=1;\n","    Index_Slot.append(i)\n","    print(\"firestt: %s\" % (filename), i+1)\n","print(\"Total Number of Fire:\", Count)\n","with open('Number fire.txt', 'w') as f:\n","        f.write(\"Total Number of Free Slot %s\\n\" % Count)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["firestt: image_4.jpg 1\n","firestt: image_4.jpg 2\n","firestt: image_4.jpg 5\n","firestt: image_4.jpg 8\n","firestt: image_4.jpg 73\n","firestt: image_4.jpg 74\n","firestt: image_4.jpg 76\n","firestt: image_4.jpg 78\n","firestt: image_4.jpg 80\n","firestt: image_4.jpg 81\n","firestt: image_4.jpg 84\n","firestt: image_4.jpg 97\n","Total Number of Fire: 12\n"],"name":"stdout"}]}]}