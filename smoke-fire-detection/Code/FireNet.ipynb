{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FireNet.ipynb","provenance":[],"authorship_tag":"ABX9TyNCDtKmH7kqlDZYOAUtCYpu"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ADZd-z8uje9i","colab_type":"code","outputId":"e05daed6-b491-497b-8ef5-3ca717e957d7","executionInfo":{"status":"ok","timestamp":1589184857399,"user_tz":-420,"elapsed":2632,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 1.x"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0u5doz2Wj2Ig","colab_type":"code","outputId":"1846a0ca-e9eb-4ce6-ab07-b597df4f237b","executionInfo":{"status":"ok","timestamp":1589184864909,"user_tz":-420,"elapsed":5735,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P6RDUScXj5e3","colab_type":"code","outputId":"54dbc68c-ff08-4ea9-f1f5-0982d5bf0638","executionInfo":{"status":"ok","timestamp":1589184891183,"user_tz":-420,"elapsed":24995,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive \n","drive.mount('/content/drive/')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N9uHfwqxj71n","colab_type":"code","outputId":"6c57d54b-86d1-4d29-c74b-ca2e7ddcb4c2","executionInfo":{"status":"ok","timestamp":1589184899568,"user_tz":-420,"elapsed":2576,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pwd"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"WnTwhU3Nj8kn","colab_type":"code","outputId":"a0cd9360-f794-49be-b04a-cf7a4db5b8c3","executionInfo":{"status":"ok","timestamp":1589184904149,"user_tz":-420,"elapsed":2607,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/Fire"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Fire\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_M8jQW2Tj-zI","colab_type":"code","outputId":"e5b7fed2-08ba-4469-c02b-fe29efc82e1a","executionInfo":{"status":"ok","timestamp":1589184908913,"user_tz":-420,"elapsed":2135,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import keras\n","import tensorflow\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import load_model\n","from IPython.display import display\n","from PIL import Image\n","import cv2\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","from skimage import transform\n","import os\n","import random\n","from keras.models import model_from_json\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"B9Oe58cTkBif","colab_type":"code","colab":{}},"source":["import keras\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from keras.preprocessing.image import ImageDataGenerator, load_img\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import random\n","import os\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n","from keras.models import model_from_json\n","import cv2\n","from skimage import transform\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TRap3fLgkH6M","colab_type":"code","colab":{}},"source":["FAST_RUN = False\n","IMAGE_WIDTH=224\n","IMAGE_HEIGHT=224\n","IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n","IMAGE_CHANNELS=3 # RGB color"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wckiYiNEkIh3","colab_type":"code","colab":{}},"source":["def CNN_Classification():\n","  model = Sequential()\n","\n","  model.add(Conv2D(64, (5, 5), strides=(4, 4), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(3, 3),strides=(2, 2) ))\n","  #model.add(Dropout(0.25))\n","\n","  model.add(Conv2D(128, (4, 4), activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n","  #model.add(Dropout(0.25))\n","\n","  model.add(Conv2D(256, (1, 1), activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n","  #model.add(Dropout(0.25))\n","\n","  model.add(Flatten())\n","  model.add(Dense(4090, activation='tanh'))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","\n","  model.add(Dense(4090, activation='tanh'))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","\n","  model.add(Dense(2, activation='softmax'))\n","  optimizer = keras.optimizers.sgd(lr = 0.001)\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  #Save Model\n","  CarsClassification_json =model.to_json()\n","  with open('modelfire2.json', \"w\") as json_file:\n","      json_file.write(CarsClassification_json)\n","      json_file.close()  \n","  model.summary()\n","  print(model.summary())\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKbElg8znueh","colab_type":"code","outputId":"f14f6369-e96e-40d5-8fa5-5a81583955a7","executionInfo":{"status":"ok","timestamp":1589184929632,"user_tz":-420,"elapsed":805,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["pos_dir= [\"/content/drive/My Drive/Fire/Datasetnew/Fire\"]\n","neg_dir= [\"/content/drive/My Drive/Fire/Datasetnew/NoFire\"]\n","\n","for pos_path in pos_dir:\n","  print(pos_path)\n","for neg_path in neg_dir:\n","  print(neg_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Fire/Datasetnew/Fire\n","/content/drive/My Drive/Fire/Datasetnew/NoFire\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p2EC1tean14o","colab_type":"code","colab":{}},"source":["def Load_Image(pos_dir, neg_dir):\n","    train_images = []\n","    train_labels = []\n","\n","    for pos_path in pos_dir:\n","      Images_Positive=os.listdir(pos_path)\n","      for image in Images_Positive:\n","          path=os.path.join(pos_path,image)\n","          img = cv2.imread(path)\n","          train_images.append(transform.resize(img,(224,224,3)))\n","          l = [1,0]\n","          train_labels.append(l)\n","    for neg_path in neg_dir:\n","      Images_Negative=os.listdir(neg_path)\n","      for image in Images_Negative:\n","          path=os.path.join(neg_path,image)\n","          img = cv2.imread(path)\n","  #       print(path)\n","          train_images.append(transform.resize(img,(224,224,3)))\n","          l = [0,1]\n","          train_labels.append(l)\n","    np.save(\"train_image_fire2\",train_images)\n","    np.save(\"train_label_fire2\",train_labels)\n","    return np.array(train_images), np.array(train_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPA-YUmWn5eo","colab_type":"code","colab":{}},"source":["def Train_Test_split(train_data, train_labels, fraction):\n","    idx = np.random.permutation(train_data.shape[0])\n","    index = int(len(train_data)*fraction)\n","    return train_data[:index], train_labels[:index], train_data[index:], train_labels[index:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ZJ3gxWhn6nw","colab_type":"code","colab":{}},"source":["def Train_Model(pos_dir, neg_dir, fraction):\n","    Train_Image,Lable_Image=Load_Image(pos_dir, neg_dir)\n","    fraction = 0.95\n","    train_data, train_labels, test_data, test_labels = Train_Test_split(Train_Image,Lable_Image, fraction)\n","    print (\"Train data size: \", len(train_data))\n","    print (\"Test data size: \", len(test_data))\n","    CNN=CNN_Classification()\n","    print (\"Train data shape: \", train_data.shape)\n","    print (\"Test data shape: \", test_data.shape)\n","    idx = np.random.permutation(train_data.shape[0])\n","    CNN.fit(train_data[idx], train_labels[idx], batch_size = 64, epochs = 30)\n","    #Save weight\n","    CNN.save_weights('weighfire2.h5')\n","    predicted_test_labels = np.argmax(CNN.predict(test_data), axis=1)\n","    test_labels = np.argmax(test_labels, axis=1)\n","    score = CNN.evaluate(test_data, test_labels, verbose=0)\n","    print('Test loss:', score[0])\n","    print('Test accuracy:', score[1])\n","    print (\"Actual test labels:\", test_labels)\n","    print (\"Predicted test labels:\", predicted_test_labels)\n","    print (\"Accuracy score:\", accuracy_score(test_labels, predicted_test_labels))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DU8Vtuo-n_34","colab_type":"code","colab":{}},"source":["def Class_object(img,Loaded_Model):\n","    img_test=[]\n","    img_test.append(transform.resize(img,(224,224,3)))\n","    Input_test=np.array(img_test)\n","    print(\"Pridict: \",Loaded_Model.predict(Input_test))\n","    if(Loaded_Model.predict(Input_test)[0][0]>0.7):\n","        print(1)\n","        return 1\n","    else:\n","        print(0)\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EeABzbO8oB0Y","colab_type":"code","outputId":"d808f05c-7064-4f54-b1c9-d0fc47389b9e","executionInfo":{"status":"ok","timestamp":1589189846583,"user_tz":-420,"elapsed":100,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["if __name__ == \"__main__\":\n","    pos_dir= [\"/content/drive/My Drive/Fire/Datasetnew/Fire\"]\n","    neg_dir= [\"/content/drive/My Drive/Fire/Datasetnew/NoFire\"]\n","    fraction= 0.95;\n","    Train_Image,Lable_Image= Load_Image(pos_dir, neg_dir) \n","    Train_Image= np.load(\"train_image_fire2.npy\")\n","    Lable_Image= np.load(\"train_label_fire2.npy\")\n","    train_data, train_labels, test_data, test_labels = Train_Test_split(Train_Image,Lable_Image, fraction)\n","    print(len(train_data))\n","    CNN=CNN_Classification()\n","    print (\"Train data shape: \", train_data.shape)\n","    print (\"Test data shape: \", test_data.shape)\n","    idx = np.random.permutation(train_data.shape[0])\n","    ntrain = len(train_data)\n","    #CNN.fit(train_data[idx], train_labels[idx], batch_size = 64, step_ber_epoch = ntrain// batch_size, epochs = 10)\n","    CNN.fit(train_data[idx], train_labels[idx], batch_size = 64, epochs = 30)\n","    #Save weight\n","    CNN.save_weights('weightfire2.h5')\n","    predicted_test_labels = np.argmax(CNN.predict(test_data), axis=1)\n","    test_labels = np.argmax(test_labels, axis=1)\n","    print (\"Actual test labels:\", test_labels)\n","    print (\"Predicted test labels:\", predicted_test_labels)\n","    print (\"Accuracy score:\", accuracy_score(test_labels, predicted_test_labels))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["2273\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_4 (Conv2D)            (None, 55, 55, 64)        4864      \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 55, 55, 64)        256       \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 27, 27, 64)        0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 24, 24, 128)       131200    \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 24, 24, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 11, 11, 128)       0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 11, 11, 256)       33024     \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 11, 11, 256)       1024      \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 6400)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4090)              26180090  \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 4090)              16360     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 4090)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4090)              16732190  \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 4090)              16360     \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 4090)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 2)                 8182      \n","=================================================================\n","Total params: 43,124,062\n","Trainable params: 43,106,806\n","Non-trainable params: 17,256\n","_________________________________________________________________\n","Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_4 (Conv2D)            (None, 55, 55, 64)        4864      \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 55, 55, 64)        256       \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 27, 27, 64)        0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 24, 24, 128)       131200    \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 24, 24, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 11, 11, 128)       0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 11, 11, 256)       33024     \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 11, 11, 256)       1024      \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 6400)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4090)              26180090  \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 4090)              16360     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 4090)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4090)              16732190  \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 4090)              16360     \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 4090)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 2)                 8182      \n","=================================================================\n","Total params: 43,124,062\n","Trainable params: 43,106,806\n","Non-trainable params: 17,256\n","_________________________________________________________________\n","None\n","Train data shape:  (2273, 224, 224, 3)\n","Test data shape:  (120, 224, 224, 3)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Epoch 1/30\n","2273/2273 [==============================] - 77s 34ms/step - loss: 1.9524 - accuracy: 0.7321\n","Epoch 2/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.4612 - accuracy: 0.8473\n","Epoch 3/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.3588 - accuracy: 0.8737\n","Epoch 4/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.3242 - accuracy: 0.8944\n","Epoch 5/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.2835 - accuracy: 0.9028\n","Epoch 6/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.2560 - accuracy: 0.9120\n","Epoch 7/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.2648 - accuracy: 0.9041\n","Epoch 8/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.2773 - accuracy: 0.9076\n","Epoch 9/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.2288 - accuracy: 0.9270\n","Epoch 10/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.2237 - accuracy: 0.9243\n","Epoch 11/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.2013 - accuracy: 0.9300\n","Epoch 12/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.2082 - accuracy: 0.9318\n","Epoch 13/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.2398 - accuracy: 0.9230\n","Epoch 14/30\n","2273/2273 [==============================] - 74s 33ms/step - loss: 0.3195 - accuracy: 0.9054\n","Epoch 15/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.2203 - accuracy: 0.9243\n","Epoch 16/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.1295 - accuracy: 0.9507\n","Epoch 17/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.1616 - accuracy: 0.9402\n","Epoch 18/30\n","2273/2273 [==============================] - 74s 33ms/step - loss: 0.1840 - accuracy: 0.9358\n","Epoch 19/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.2245 - accuracy: 0.9199\n","Epoch 20/30\n","2273/2273 [==============================] - 74s 33ms/step - loss: 0.1479 - accuracy: 0.9512\n","Epoch 21/30\n","2273/2273 [==============================] - 76s 33ms/step - loss: 0.1171 - accuracy: 0.9644\n","Epoch 22/30\n","2273/2273 [==============================] - 74s 33ms/step - loss: 0.0962 - accuracy: 0.9644\n","Epoch 23/30\n","2273/2273 [==============================] - 76s 33ms/step - loss: 0.1254 - accuracy: 0.9525\n","Epoch 24/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.1660 - accuracy: 0.9454\n","Epoch 25/30\n","2273/2273 [==============================] - 75s 33ms/step - loss: 0.1666 - accuracy: 0.9428\n","Epoch 26/30\n","2273/2273 [==============================] - 74s 33ms/step - loss: 0.1379 - accuracy: 0.9507\n","Epoch 27/30\n","2273/2273 [==============================] - 74s 33ms/step - loss: 0.1341 - accuracy: 0.9525\n","Epoch 28/30\n","2273/2273 [==============================] - 74s 33ms/step - loss: 0.1445 - accuracy: 0.9494\n","Epoch 29/30\n","2273/2273 [==============================] - 74s 33ms/step - loss: 0.2042 - accuracy: 0.9402\n","Epoch 30/30\n","2273/2273 [==============================] - 74s 32ms/step - loss: 0.1725 - accuracy: 0.9454\n","Actual test labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1]\n","Predicted test labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1]\n","Accuracy score: 0.9333333333333333\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3QdXewrL0nvV","colab_type":"code","outputId":"ed07fc53-8e1e-4e16-f73f-c3c4bce64e83","executionInfo":{"status":"ok","timestamp":1589189944669,"user_tz":-420,"elapsed":3214,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Load Model\n","json_file= open('modelfire2.json','r')\n","loaded_model_json= json_file.read()\n","json_file.close()\n","Loaded_Model = model_from_json(loaded_model_json)\n","#Load weights into new model\n","Loaded_Model.load_weights(\"weightfire2.h5\")\n","print(\"Loaded\")"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2ZHCyqRL0tUr","colab_type":"code","colab":{}},"source":["def Load_Image(test_dir):\n","    test_images = []\n","    for test_path in test_dir:\n","      Images_Positive=os.listdir(test_path)\n","      for image in Images_Positive:\n","          path=os.path.join(test_path,image)\n","          img = cv2.imread(path)\n","          test_images.append(transform.resize(img,(224,224,3)))\n","    return np.array(test_images)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"urnIao8F01jT","colab_type":"code","colab":{}},"source":["def load_images_from_folder(folder):\n","    images = []\n","    for filename in os.listdir(folder):\n","        img = cv2.imread(os.path.join(folder,filename))\n","        print(filename)\n","        if img is not None:\n","            images.append(img);\n","    return images"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0YP67VLa04bS","colab_type":"code","colab":{}},"source":["folder=\"/content/drive/My Drive/Fire/Testnew/NoFire_2\"\n","Predict_Slot=[]\n","filename_array = []\n","for filename in os.listdir(folder):\n","    images = []\n","    img = cv2.imread(os.path.join(folder,filename))\n","    images.append(transform.resize(img, (224,224,3)))\n","    images= np.array(images)\n","    if(Loaded_Model.predict(images)[0][0]>0.7):\n","      Predict_Slot.append(1)\n","      #print(\"BusySlot: %s\" % (filename))\n","      filename_array += [\"fire: %s\" % (filename)]\n","\n","    else:\n","      Predict_Slot.append(0)\n","      #print(\"FreeSlot: %s\" % (filename))\n","      filename_array += [\"nofire: %s\" % (filename)]\n","with open('Checkdata.txt', 'w') as f:\n","    for item in filename_array:\n","        f.write(\"%s\\n\" % item)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L3LCsqmS08ta","colab_type":"code","outputId":"76e4d594-0eea-4777-b22f-d37fb9737b87","executionInfo":{"status":"ok","timestamp":1589191001550,"user_tz":-420,"elapsed":995,"user":{"displayName":"Hạnh Lê Bích","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1MKBkDg0aaeArAh3D1UZI-oFQ7-5ouWUyaRyf=s64","userId":"13667524904205959784"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["#Check Fire Slot\n","Index_Slot= []\n","Count=0;\n","for i in range(len(Predict_Slot)):\n","  if(Predict_Slot[i]==1):\n","    Count +=1;\n","    Index_Slot.append(i)\n","    print(\"firestt: %s\" % (filename), i+1)\n","print(\"Total Number of Fire:\", Count)\n","with open('Number fire.txt', 'w') as f:\n","        f.write(\"Total Number of Free Slot %s\\n\" % Count)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["firestt: nofiresamp6_frame50.jpg 25\n","firestt: nofiresamp6_frame50.jpg 40\n","firestt: nofiresamp6_frame50.jpg 42\n","firestt: nofiresamp6_frame50.jpg 45\n","firestt: nofiresamp6_frame50.jpg 47\n","firestt: nofiresamp6_frame50.jpg 67\n","firestt: nofiresamp6_frame50.jpg 72\n","firestt: nofiresamp6_frame50.jpg 93\n","Total Number of Fire: 8\n"],"name":"stdout"}]}]}